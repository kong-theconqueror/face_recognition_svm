{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f16f931a",
   "metadata": {},
   "source": [
    "Train face recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "14a880a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Optional, Iterable\n",
    "\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "56145ba2-6252-4ba3-922f-5249827c9d32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CẤU HÌNH ĐƯỜNG DẪN\n",
    "# =========================\n",
    "ROOT_DIR = os.getcwd()\n",
    "DATA_DIR = os.path.join(ROOT_DIR, \"data\")\n",
    "LFW_DIR = os.path.join(DATA_DIR, \"lfw-deepfunneled\", \"lfw-deepfunneled\")\n",
    "\n",
    "TRAIN_CSV = os.path.join(DATA_DIR, \"peopleDevTrain.csv\")\n",
    "TEST_CSV = os.path.join(DATA_DIR, \"peopleDevTest.csv\")\n",
    "\n",
    "MODEL_PATH = os.path.join(ROOT_DIR, \"models\", \"face_svc.pkl\")\n",
    "ENC_CACHE = os.path.join(ROOT_DIR, \"models\", \"train_encodings.pkl\")\n",
    "\n",
    "DEFAULT_TEST_DIR = os.path.join(ROOT_DIR, \"test\")\n",
    "DEFAULT_TEST_OUT = os.path.join(ROOT_DIR, \"test\", \"test_results.csv\")\n",
    "DEFAULT_EVAL_DIR = os.path.join(ROOT_DIR, \"test_100_peoples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f719d34c-b0ef-4e3c-8f0d-137be6b54ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# CẤU HÌNH FACE PIPELINE\n",
    "# =========================\n",
    "DETECT_MODEL = \"cnn\"         # \"hog\" hoặc \"cnn\"\n",
    "LANDMARKS_MODEL = \"large\"    # \"small\" hoặc \"large\"\n",
    "UPSAMPLE = 0                # 0 nhanh, tăng lên (1,2) bắt mặt nhỏ tốt hơn nhưng chậm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9e9f97b-1eeb-43b2-9154-fc2ccd7bf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# ĐỌC DANH SÁCH DỮ LIỆU\n",
    "# =========================\n",
    "def read_people(csv_path: Path) -> List[Tuple[str, int]]:\n",
    "    \"\"\"Đọc danh sách người và số lượng ảnh cần dùng từ file CSV.\"\"\"\n",
    "    people = []\n",
    "    with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            name = row[\"name\"]\n",
    "            count = int(row[\"images\"])\n",
    "            people.append((name, count))\n",
    "    return people\n",
    "\n",
    "\n",
    "def image_paths_for_person(name: str, count: int) -> List[str]:\n",
    "    \"\"\"Sinh danh sách đường dẫn ảnh cho một người theo định dạng LFW.\"\"\"\n",
    "    paths = []\n",
    "    for idx in range(1, count + 1):\n",
    "        filename = f\"{name}_{idx:04d}.jpg\"\n",
    "        paths.append(os.path.join(LFW_DIR, name, filename))\n",
    "    return paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9aadbbe5-6a65-4bdc-a921-0b0cc5cec7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TIỀN XỬ LÝ ẢNH / ENCODING\n",
    "# =========================\n",
    "def _box_area(box: Tuple[int, int, int, int]) -> int:\n",
    "    \"\"\"Tính diện tích box (top, right, bottom, left).\"\"\"\n",
    "    top, right, bottom, left = box\n",
    "    return max(0, bottom - top) * max(0, right - left)\n",
    "\n",
    "\n",
    "def encode_image(\n",
    "    image_path: str,\n",
    "    detect_model: str = DETECT_MODEL,\n",
    "    landmarks_model: str = LANDMARKS_MODEL,\n",
    "    upsample: int = UPSAMPLE,\n",
    "    choose_largest_face: bool = True\n",
    ") -> Optional[np.ndarray]:\n",
    "    \"\"\"\n",
    "    Đọc ảnh và trả về encoding đầu tiên (hoặc mặt lớn nhất nếu choose_largest_face=True).\n",
    "\n",
    "    Pipeline:\n",
    "    - Kiểm tra file\n",
    "    - Load ảnh\n",
    "    - Detect face locations (hog/cnn)\n",
    "    - (Tuỳ chọn) chọn 1 mặt lớn nhất nếu có nhiều mặt\n",
    "    - Face encodings (embedding 128D) với landmarks model (small/large)\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(image_path):\n",
    "        print(f\"[BỎ QUA] Không tìm thấy ảnh: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"[BỎ QUA] Lỗi đọc ảnh: {image_path} | {e}\")\n",
    "        return None\n",
    "\n",
    "    # 1) Detect mặt (bounding boxes)\n",
    "    try:\n",
    "        locs = face_recognition.face_locations(\n",
    "            image,\n",
    "            number_of_times_to_upsample=upsample,\n",
    "            model=detect_model\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[BỎ QUA] Lỗi detect face: {image_path} | {e}\")\n",
    "        return None\n",
    "\n",
    "    if not locs:\n",
    "        print(f\"[BỎ QUA] Không tìm thấy khuôn mặt trong ảnh: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # 2) Nếu có nhiều mặt: chọn mặt lớn nhất (thường là chủ thể)\n",
    "    if choose_largest_face and len(locs) > 1:\n",
    "        locs = [max(locs, key=_box_area)]\n",
    "\n",
    "    # 3) Tạo embedding 128D dựa trên locations đã biết\n",
    "    try:\n",
    "        encs = face_recognition.face_encodings(\n",
    "            image,\n",
    "            known_face_locations=locs,\n",
    "            model=landmarks_model  # \"small\" hoặc \"large\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[BỎ QUA] Lỗi tạo encodings: {image_path} | {e}\")\n",
    "        return None\n",
    "\n",
    "    if not encs:\n",
    "        print(f\"[BỎ QUA] Không tạo được encoding cho ảnh: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    return encs[0]\n",
    "\n",
    "\n",
    "def build_dataset(csv_path: Path):\n",
    "    \"\"\"Từ file CSV sinh X (encodings) và y (nhãn).\"\"\"\n",
    "    people = read_people(csv_path)\n",
    "    X, y = [], []\n",
    "    for name, count in people:\n",
    "        for img_path in image_paths_for_person(name, count):\n",
    "            enc = encode_image(img_path)\n",
    "            if enc is None:\n",
    "                continue\n",
    "            X.append(enc)\n",
    "            y.append(name)\n",
    "\n",
    "    if not X:\n",
    "        raise RuntimeError(f\"Không tạo được dữ liệu từ {csv_path}\")\n",
    "\n",
    "    return np.vstack(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e484508b-6999-4469-b5b5-36a4fcbcf91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# HUẤN LUYỆN MODEL\n",
    "# =========================\n",
    "def train(train_csv: Path = TRAIN_CSV, model_path: Path = MODEL_PATH):\n",
    "    \"\"\"Huấn luyện SVC và lưu model.\"\"\"\n",
    "    print(f\"[TRAIN] Đang xây dựng tập train từ {train_csv}\")\n",
    "    X_train, y_train = build_dataset(train_csv)\n",
    "    print(f\"[TRAIN] Tổng mẫu train: {len(y_train)}\")\n",
    "\n",
    "    clf = SVC(kernel=\"linear\", probability=True, class_weight=\"balanced\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"[TRAIN] Huấn luyện xong.\")\n",
    "\n",
    "    model_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(model_path, \"wb\") as f:\n",
    "        pickle.dump(clf, f)\n",
    "    print(f\"[TRAIN] Đã lưu model vào {model_path}\")\n",
    "\n",
    "    # Lưu cache encodings để predict_dist khỏi phải build lại lâu\n",
    "    ENC_CACHE.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(ENC_CACHE, \"wb\") as f:\n",
    "        pickle.dump({\"X_train\": X_train, \"y_train\": y_train}, f)\n",
    "    print(f\"[TRAIN] Đã lưu cache encodings vào {ENC_CACHE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be01496-7a2e-4c6c-9e09-e391c59d675b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] Đang xây dựng tập train từ C:\\Users\\PC-09\\Documents\\Projects\\face_recognition_svm\\data\\peopleDevTrain.csv\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
